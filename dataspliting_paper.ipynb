{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import time\n",
    "from scipy.stats import sem\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spliting percentages\n",
    "train = [0.02,0.05,0.07]\n",
    "more = np.linspace(0.10,0.95,18)\n",
    "train = np.hstack([train,more])\n",
    "\n",
    "# Creates the table for the analysis\n",
    "table = pd.DataFrame(columns=['models','train %','fit time','pred time','acc_train','pre_train','rec_train','acc_test','pre_test','rec_test'])\n",
    "\n",
    "# Models to be used\n",
    "models = [GradientBoostingClassifier(random_state=2),KNeighborsClassifier(),LinearSVC(random_state=5),LogisticRegression(random_state=2)\n",
    ",RandomForestClassifier(random_state=2),RidgeClassifier(random_state=2),XGBClassifier()]\n",
    "\n",
    "# Own data\n",
    "own_data = pd.read_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select cols to use to train the model\n",
    "X = own_data[['Latitude','Longitude','Speed','Hours','Month']]\n",
    "\n",
    "# Target Variable\n",
    "y = own_data['target']\n",
    "enconder = OrdinalEncoder()\n",
    "y = enconder.fit_transform(np.array(y).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each training percentage\n",
    "\n",
    "for set in train:\n",
    "\n",
    "    for i in range(10):\n",
    "        \n",
    "        xtrain, xtest, ytrain, ytest = train_test_split(X,y,train_size=set,shuffle=True)\n",
    "\n",
    "        for model in models:\n",
    "\n",
    "            time1 = time.time()\n",
    "            model.fit(xtrain,ytrain)\n",
    "            time2 = time.time()\n",
    "            tmpT = time2-time1\n",
    "            ypredt = model.predict(xtrain)\n",
    "            acc_train = accuracy_score(ytrain,ypredt)\n",
    "            pre_train = precision_score(ytrain,ypredt)\n",
    "            rec_train = recall_score(ytrain,ypredt)\n",
    "            time1 = time.time()\n",
    "            ypred = model.predict(xtest)\n",
    "            acc_test = accuracy_score(ytest,ypred)\n",
    "            pre_test = precision_score(ytest,ypred)\n",
    "            rec_test = recall_score(ytest,ypred)\n",
    "            time2 = time.time()\n",
    "            tmpTT = time2-time1\n",
    "            name = model.__class__.__name__\n",
    "\n",
    "            table = table.append({'models':name,'train %':set,'fit time':tmpT,'pred time':tmpTT,\n",
    "                                'acc_train':acc_train,'pre_train':pre_train,'rec_train':rec_train,\n",
    "                                'acc_test':acc_test,'pre_test':pre_test,'rec_test':rec_test}, ignore_index = True)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimates mean and sem metrics for each model and number of variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_means = pd.DataFrame(columns=['model','train %','mean_fit','mean_pred','mean_acc','mean_pre','mean_rec','sem_fit','sem_pred','sem_acc','sem_pre','sem_rec'])\n",
    "\n",
    "for model in pd.unique(table['models']):\n",
    "    \n",
    "    new_data = table[table['models']==model]\n",
    "\n",
    "    for set in pd.unique(new_data['train %']):\n",
    "\n",
    "        set_data = new_data[new_data['train %'] == set]\n",
    "        \n",
    "        mean_time = np.mean(set_data['fit time'])\n",
    "        sem_time = sem(set_data['fit time'])\n",
    "\n",
    "        mean_pred = np.mean(set_data['pred time'])\n",
    "        sem_pred = sem(set_data['pred time'])\n",
    "\n",
    "        mean_acc = np.mean(set_data['acc_test'])\n",
    "        sem_acc = sem(set_data['acc_test'])\n",
    "\n",
    "        mean_pre = np.mean(set_data['pre_test'])\n",
    "        sem_pre = sem(set_data['pre_test'])\n",
    "\n",
    "        mean_rec = np.mean(set_data['rec_test'])\n",
    "        sem_rec = sem(set_data['rec_test'])\n",
    "\n",
    "        results = {'model':model,'train %':set,'mean_fit':mean_time,'mean_pred':mean_pred,'mean_acc':mean_acc,'mean_pre':mean_pre,'mean_rec':mean_rec\n",
    "                    ,'sem_fit':sem_time,'sem_pred':sem_pred,'sem_acc':sem_acc,'sem_pre':sem_pre,'sem_rec':sem_rec}\n",
    "\n",
    "        table_means = table_means.append(results,ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization\n",
    "\n",
    "datasplitByBoat is regarding sampling by boat approach, not considered for the sake of simplicity, but it was commented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,15))\n",
    "ftms = ['o','^','s','v','x','H','*']\n",
    "colors = [(43/255,57/255,136/255),(42/255,196/255,244/255),(251/255,174/255,39/255)]\n",
    "size = 4\n",
    "label = ['GrBo','RaFo','XGBo']\n",
    "i = 0\n",
    "lab = np.array(pd.unique(table_means['train %']),dtype=float)*100\n",
    "for model in ['GradientBoostingClassifier', 'RandomForestClassifier','XGBClassifier']:\n",
    "\n",
    "    plt.subplot(5,2,1)\n",
    "    plt.title('Sample unit by point')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "\n",
    "    plt.xticks(np.arange(10,100,10),color = 'w')\n",
    "    plt.errorbar(np.round(lab,2)[3:-1],table_means[table_means['model']==model]['mean_acc'][3:-1]*100\n",
    "                ,yerr=table_means[table_means['model']==model]['sem_acc'][3:-1]*100,capsize=3,fmt=ftms[i],color = colors[i] ,markersize= size)\n",
    "    #plt.yticks(ticks=[96,97.5,99.0,100])\n",
    "\n",
    "    #plt.subplot(5,2,2)\n",
    "    #plt.title('Sample unit by boat')\n",
    "    #plt.xticks(np.arange(10,100,10),color = 'w')\n",
    "    #plt.errorbar(np.round(lab,2)[3:-1],datasplitByBoat[datasplitByBoat['model']==model]['mean_acc'][3:-1]*100\n",
    "    #            ,yerr=datasplitByBoat[datasplitByBoat['model']==model]['sem_acc'][3:-1]*100,capsize=3,fmt=ftms[i], color = colors[i] ,markersize = size)\n",
    "    #plt.yticks(ticks=[80,85.0,90.0,95.0])\n",
    "\n",
    "    plt.subplot(5,2,3)\n",
    "    plt.ylabel('Precision (%)')\n",
    "    plt.xticks(np.arange(10,100,10),color = 'w')\n",
    "    plt.errorbar(np.round(lab,2)[3:-1],table_means[table_means['model']==model]['mean_pre'][3:-1]*100\n",
    "                ,yerr=table_means[table_means['model']==model]['sem_pre'][3:-1]*100,capsize=3,fmt=ftms[i], color = colors[i] ,markersize = size)\n",
    "    #plt.yticks(ticks=[97,98,99,100])\n",
    "\n",
    "    #plt.subplot(5,2,4)\n",
    "    #plt.xticks(np.arange(10,100,10),color = 'w')\n",
    "    #plt.errorbar(np.round(lab,2)[3:-1],datasplitByBoat[datasplitByBoat['model']==model]['mean_pre'][3:-1]*100\n",
    "    #            ,yerr=datasplitByBoat[datasplitByBoat['model']==model]['sem_pre'][3:-1]*100,capsize=3,fmt=ftms[i],color = colors[i] , markersize = size)\n",
    "    #plt.yticks(ticks=[91,93,95,97])\n",
    "\n",
    "    plt.subplot(5,2,5)\n",
    "    plt.ylabel('Recall (%)')\n",
    "    plt.xticks(np.arange(10,100,10))\n",
    "    plt.errorbar(np.round(lab,2)[3:-1],table_means[table_means['model']==model]['mean_rec'][3:-1]*100\n",
    "                ,yerr=table_means[table_means['model']==model]['sem_rec'][3:-1]*100,capsize=3,fmt=ftms[i], color = colors[i] ,markersize = size)\n",
    "\n",
    "    #plt.subplot(5,2,6)\n",
    "    #plt.xticks(np.arange(10,100,10))\n",
    "    #plt.errorbar(np.round(lab,2)[3:-1],datasplitByBoat[datasplitByBoat['model']==model]['mean_rec'][3:-1]*100\n",
    "    #            ,yerr=datasplitByBoat[datasplitByBoat['model']==model]['sem_rec'][3:-1]*100,capsize=3,fmt=ftms[i],color = colors[i] , markersize = size)\n",
    "    plt.xlabel('Percentage of training data (%)',{'x':-0.1,'y':0})\n",
    "\n",
    "    ''' plt.subplot(5,2,7)\n",
    "    plt.ylabel('Training time (seconds)')\n",
    "    plt.xticks(np.arange(10,100,10),color = 'w')\n",
    "    plt.errorbar(np.round(lab,2)[3:-1],datasplitByPoint[datasplitByPoint['model']==model]['mean_fit'][3:-1]\n",
    "                ,yerr=datasplitByPoint[datasplitByPoint['model']==model]['sem_fit'][3:-1],capsize=3,fmt=ftms[i], color = colors[i] ,markersize = size)\n",
    "    plt.yticks(ticks=[0,10,20,30])\n",
    "\n",
    "    plt.subplot(5,2,8)\n",
    "    plt.xticks(np.arange(10,100,10),color = 'w')\n",
    "    plt.errorbar(np.round(lab,2)[3:-1],datasplitByBoat[datasplitByBoat['model']==model]['mean_fit'][3:-1]\n",
    "                ,yerr=datasplitByBoat[datasplitByBoat['model']==model]['sem_fit'][3:-1],capsize=3,fmt=ftms[i],color = colors[i] , markersize = size)\n",
    "    plt.yticks(ticks=[0,10,20,30])\n",
    "\n",
    "    plt.subplot(5,2,9)\n",
    "    plt.ylabel('Predict time (seconds)')\n",
    "    plt.errorbar(np.round(lab,2)[3:-1],datasplitByPoint[datasplitByPoint['model']==model]['mean_pred'][3:-1]\n",
    "                ,yerr=datasplitByPoint[datasplitByPoint['model']==model]['sem_pred'][3:-1],capsize=3,fmt=ftms[i], color = colors[i] ,markersize = size)\n",
    "    plt.xticks(np.arange(10,100,10))\n",
    "    plt.yticks(ticks=[0,0.75,1.75,2.5])\n",
    "    #plt.xlabel('Data train set')\n",
    "    \n",
    "    plt.subplot(5,2,10)\n",
    "    plt.errorbar(np.round(lab,2)[3:-1],datasplitByBoat[datasplitByBoat['model']==model]['mean_pred'][3:-1]\n",
    "            ,yerr=datasplitByBoat[datasplitByBoat['model']==model]['sem_pred'][3:-1],capsize=3,fmt=ftms[i],color = colors[i] , markersize = size)\n",
    "    plt.xticks(np.arange(10,100,10))\n",
    "    plt.yticks(ticks=[0,0.75,1.75,2.5])\n",
    "    plt.xlabel('Data train set',{'x':-0.1,'y':0})'''\n",
    "\n",
    "    i+=1\n",
    "plt.legend(['GrBo','RaFo','XGBo'], bbox_to_anchor = (1.3,3.45),ncol = 1)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
